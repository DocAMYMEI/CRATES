{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910d6475",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Regression-Discontinuity (RD) Event Study (Volume Version, Direct Plotting)\n",
    "---------------------------------------------------------------------------\n",
    "This script runs the RDD analysis for Volume and displays plots directly.\n",
    "No files are exported.\n",
    "\"\"\"\n",
    "\n",
    "import pathlib\n",
    "import warnings\n",
    "from typing import List, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 1)  Dependency checks & Global parameters\n",
    "try:\n",
    "    import statsmodels.api as sm\n",
    "    HAVE_SM = True\n",
    "except Exception as e:\n",
    "    warnings.warn(f\"statsmodels unavailable ({e}); falling back to NumPy OLS.\")\n",
    "    HAVE_SM = False\n",
    "try:\n",
    "    from scipy import stats as sps\n",
    "    HAVE_SCIPY = True\n",
    "except Exception: HAVE_SCIPY = False\n",
    "\n",
    "BANDWIDTHS = [10, 20]\n",
    "OUTCOME    = \"vol\" # Changed to 'vol'\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 2)  Helper functions\n",
    "def read_csv_robustly(path: pathlib.Path, engine: str = 'c', sep=','):\n",
    "    encodings_to_try = ['utf-8', 'utf-8-sig', 'gbk', 'gb2312', 'latin-1']\n",
    "    if engine == 'python': sep = None\n",
    "    for enc in encodings_to_try:\n",
    "        try: return pd.read_csv(path, encoding=enc, engine=engine, sep=sep)\n",
    "        except (UnicodeDecodeError, UnicodeError, pd.errors.ParserError): continue\n",
    "    raise ValueError(f\"Failed to read or parse '{path}'.\")\n",
    "\n",
    "def std_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df.columns = (df.columns.str.lower().str.replace(\" \", \"\").str.replace(\".\", \"\", regex=False).str.strip())\n",
    "    return df\n",
    "\n",
    "def load_data(path: pathlib.Path) -> pd.DataFrame:\n",
    "    \"\"\"Read a CSV, clean the Vol. column, and return a date-sorted DataFrame.\"\"\"\n",
    "    df = read_csv_robustly(path)\n",
    "    df = std_cols(df)\n",
    "    if \"date\" not in df.columns or \"vol\" not in df.columns:\n",
    "        raise ValueError(f\"File '{path}' must contain 'Date' and 'Vol.' columns.\")\n",
    "    df = df.rename(columns={\"vol\": OUTCOME})\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"date\"])\n",
    "    def parse_volume(vol_str):\n",
    "        vol_str = str(vol_str).strip().upper()\n",
    "        if pd.isna(vol_str) or vol_str == '': return np.nan\n",
    "        multipliers = {'K': 1e3, 'M': 1e6, 'B': 1e9}\n",
    "        if vol_str and vol_str[-1] in multipliers:\n",
    "            try:\n",
    "                return float(vol_str[:-1]) * multipliers[vol_str[-1]]\n",
    "            except ValueError:\n",
    "                return np.nan\n",
    "        return pd.to_numeric(vol_str, errors='coerce')\n",
    "    df[OUTCOME] = df[OUTCOME].apply(parse_volume)\n",
    "    return df.sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "def ols_numpy(y: np.ndarray, X: np.ndarray):\n",
    "    n, k = X.shape\n",
    "    beta  = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "    resid = y - X @ beta\n",
    "    sigma2 = (resid @ resid) / (n - k)\n",
    "    cov = sigma2 * np.linalg.inv(X.T @ X)\n",
    "    se = np.sqrt(np.diag(cov))\n",
    "    p = (2 * (1 - sps.t.cdf(np.abs(beta / se), df=n - k)) if HAVE_SCIPY else 2 * (1 - np.exp(-0.5 * (beta / se) ** 2) / np.sqrt(2 * np.pi) / np.abs(beta / se)))\n",
    "    return beta, p, cov\n",
    "\n",
    "def rd_design(df: pd.DataFrame, event_date: pd.Timestamp, bw: int, y_col: str):\n",
    "    df = df.copy() # Avoid SettingWithCopyWarning\n",
    "    df['D'], df['T'] = (df['Date'] - event_date).dt.days, (df['Date'] >= event_date).astype(int)\n",
    "    win = df[df['D'].between(-bw, bw)].dropna(subset=[y_col])\n",
    "    X_df = win[['T', 'D']].astype(float)\n",
    "    X_df['TD'] = X_df['T'] * X_df['D']\n",
    "    X, y = np.column_stack([np.ones(len(X_df)), X_df.to_numpy()]), win[y_col].to_numpy(float)\n",
    "    cols = ['const', 'T', 'D', 'TD']\n",
    "    if HAVE_SM:\n",
    "        model = sm.OLS(y, X).fit(cov_type='HAC', cov_kwds={'maxlags': 3})\n",
    "        model.colnames, model.params, model.pvalues, model.cov = cols, pd.Series(model.params, index=cols), pd.Series(model.pvalues, index=cols), model.cov_params()\n",
    "        return win, model\n",
    "    else:\n",
    "        beta, p, cov = ols_numpy(y, X)\n",
    "        class Result:\n",
    "            params, pvalues, cov, colnames = pd.Series(beta, index=cols), pd.Series(p, index=cols), pd.DataFrame(cov, index=cols, columns=cols), cols\n",
    "            def conf_int(self):\n",
    "                se = np.sqrt(np.diag(self.cov))\n",
    "                return pd.DataFrame(np.column_stack([self.params - 1.96 * se, self.params + 1.96 * se]), index=cols, columns=['low', 'high'])\n",
    "        return win, Result()\n",
    "\n",
    "def get_ci(model, param: str):\n",
    "    ci = model.conf_int()\n",
    "    return ci.loc[param] if isinstance(ci, pd.DataFrame) else (ci[model.colnames.index(param), 0], ci[model.colnames.index(param), 1])\n",
    "\n",
    "def rd_plot(win: pd.DataFrame, model, evt: pd.Timestamp, bw: int, asset: str, y_col: str):\n",
    "    grid = np.arange(-bw, bw + 1)\n",
    "    α, τ, β, γ = (model.params[k] for k in ['const', 'T', 'D', 'TD'])\n",
    "    μ_L, μ_R = α + β * grid, α + τ + (β + γ) * grid\n",
    "    cov = model.cov if isinstance(model.cov, np.ndarray) else model.cov.to_numpy()\n",
    "    X_L = np.column_stack([np.ones_like(grid), np.zeros_like(grid), grid, np.zeros_like(grid)])\n",
    "    X_R = np.column_stack([np.ones_like(grid), np.ones_like(grid),  grid, grid])\n",
    "    se_L, se_R = np.sqrt(np.einsum('ij,jk,ik->i', X_L, cov, X_L)), np.sqrt(np.einsum('ij,jk,ik->i', X_R, cov, X_R))\n",
    "    upper_L, lower_L, upper_R, lower_R = μ_L + 1.96 * se_L, μ_L - 1.96 * se_L, μ_R + 1.96 * se_R, μ_R - 1.96 * se_R\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    colors = win['D'].apply(lambda x: 'royalblue' if x < 0 else 'firebrick')\n",
    "    plt.scatter(win['D'], win[y_col], s=18, color=colors, alpha=0.7, zorder=2)\n",
    "    plt.plot(grid[grid < 0], μ_L[grid < 0], color='forestgreen', lw=2)\n",
    "    plt.plot(grid[grid >= 0], μ_R[grid >= 0], color='forestgreen', lw=2)\n",
    "    plt.fill_between(grid[grid < 0], lower_L[grid < 0], upper_L[grid < 0], color='grey', alpha=0.3)\n",
    "    plt.fill_between(grid[grid >= 0], lower_R[grid >= 0], upper_R[grid >= 0], color='grey', alpha=0.3)\n",
    "    plt.axvline(0, color='crimson', lw=2, ls='--')\n",
    "    plt.title(f\"{asset} | {evt.date()} | ±{bw}d   τ̂ = {model.params['T']:.4f} (p = {model.pvalues['T']:.3g})\")\n",
    "    plt.xlabel(\"Days relative to event\")\n",
    "    plt.ylabel(y_col.capitalize())\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 3)  Main script\n",
    "if __name__ == \"__main__\":\n",
    "    # --- ADJUSTED: Data Loading ---\n",
    "    print(\"--- Loading Benchmark Data ---\")\n",
    "    # Define the directory where benchmark CSVs are located.\n",
    "    BENCHMARK_DIR = pathlib.Path(\"./benchmark\")\n",
    "    if not BENCHMARK_DIR.is_dir(): raise FileNotFoundError(f\"Benchmark directory '{BENCHMARK_DIR}' not found.\")\n",
    "    \n",
    "    bench_files = [\"Gold.csv\", \"Nasdaq100.csv\", \"SPY.csv\"]\n",
    "    # Load each file from the benchmark directory.\n",
    "    loaded_data = {\n",
    "        pathlib.Path(f).stem: load_data(BENCHMARK_DIR / f) for f in bench_files\n",
    "    }\n",
    "    print(f\"  • Loaded: {', '.join(loaded_data.keys())}\")\n",
    "    \n",
    "    print(\"\\n--- Loading Crypto Asset Data ---\")\n",
    "    CRYPTO_DATA_DIR = pathlib.Path(\"./crypto_data\")\n",
    "    if not CRYPTO_DATA_DIR.is_dir(): raise FileNotFoundError(f\"Directory '{CRYPTO_DATA_DIR}' not found.\")\n",
    "    crypto_files = list(CRYPTO_DATA_DIR.glob(\"*.csv\"))\n",
    "    if not crypto_files: raise FileNotFoundError(f\"No CSV files found in '{CRYPTO_DATA_DIR}'.\")\n",
    "    for f_path in crypto_files:\n",
    "        asset_name = f_path.stem\n",
    "        loaded_data[asset_name] = load_data(f_path)\n",
    "    print(f\"  • Found and loaded {len(crypto_files)} crypto assets.\")\n",
    "\n",
    "    print(\"\\n--- Loading Wide-Format Event Calendar Data ---\")\n",
    "    EVENTS_DIR = pathlib.Path(\"./events\")\n",
    "    train_events_file, test_events_file = EVENTS_DIR / \"training_set.csv\", EVENTS_DIR / \"test_set.csv\"\n",
    "    if not EVENTS_DIR.is_dir(): raise FileNotFoundError(f\"Directory '{EVENTS_DIR}' not found.\")\n",
    "    if not train_events_file.is_file(): raise FileNotFoundError(f\"File '{train_events_file}' not found.\")\n",
    "    if not test_events_file.is_file(): raise FileNotFoundError(f\"File '{test_events_file}' not found.\")\n",
    "    \n",
    "    events = {}\n",
    "    def load_wide_events(path: pathlib.Path, suffix: str) -> dict:\n",
    "        local_events = {}\n",
    "        df = read_csv_robustly(path, engine='python')\n",
    "        df = std_cols(df)\n",
    "        for group_name in df.columns:\n",
    "            local_events[f\"{group_name}{suffix}\"] = pd.to_datetime(df[group_name].dropna(), errors='coerce').dropna()\n",
    "        return local_events\n",
    "\n",
    "    if train_events_file.is_file(): events.update(load_wide_events(train_events_file, \"_train\"))\n",
    "    if test_events_file.is_file(): events.update(load_wide_events(test_events_file, \"_test\"))\n",
    "    print(f\"  • Total unique event groups to process: {len(events)}\")\n",
    "    print(\"----------------------------------------------------\\n\")\n",
    "    \n",
    "    for asset, df in loaded_data.items():\n",
    "        print(f\"\\n=== {asset} ====================================================\")\n",
    "        if df.empty or OUTCOME not in df.columns:\n",
    "            warnings.warn(f\"'{OUTCOME}' column not found or DataFrame is empty for {asset}. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        for group, dates in events.items():\n",
    "            for d in dates:\n",
    "                evt = pd.to_datetime(d)\n",
    "                if evt not in df['Date'].values: continue\n",
    "                \n",
    "                for bw in BANDWIDTHS:\n",
    "                    try:\n",
    "                        win, model = rd_design(df, evt, bw, OUTCOME)\n",
    "                        if len(win) < 10:\n",
    "                            warnings.warn(f\"Skipping {asset} on {d.date()} (±{bw}d) due to insufficient data.\")\n",
    "                            continue\n",
    "                        \n",
    "                        ci_lo, ci_hi = get_ci(model, \"T\")\n",
    "                        print(f\"{d.date()} {group:<22} ±{bw:>2}d \"\n",
    "                              f\"τ̂={model.params['T']:.6f} \"\n",
    "                              f\"p={model.pvalues['T']:.4f} \"\n",
    "                              f\"CI=({ci_lo:.6f}, {ci_hi:.6f}) \"\n",
    "                              f\"N={len(win)}\")\n",
    "                        \n",
    "                        rd_plot(win, model, evt, bw, asset, OUTCOME)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Could not process event {d.date()} for {asset} (±{bw}d). Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
